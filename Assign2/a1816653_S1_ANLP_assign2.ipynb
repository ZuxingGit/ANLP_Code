{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6730fecf",
   "metadata": {},
   "source": [
    "# Assignment 2 \n",
    "### \\<Zuxing Wu> \\<a1816653>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df2aac6",
   "metadata": {},
   "source": [
    "## A. Tasks as specified for your team structure\n",
    "\n",
    "**One person work: Information Retrieval and Extraction system**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afa441f",
   "metadata": {},
   "source": [
    "### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bb75429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>topic</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17307</td>\n",
       "      <td>Marlise Simons</td>\n",
       "      <td>1/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>architecture</td>\n",
       "      <td>PARIS  ?   When the Islamic State was about to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17292</td>\n",
       "      <td>Andy Newman</td>\n",
       "      <td>31/12/2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>art</td>\n",
       "      <td>Angels are everywhere in the Mu?iz family?s ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17298</td>\n",
       "      <td>Emma G. Fitzsimmons</td>\n",
       "      <td>2/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>Finally. The Second Avenue subway opened in Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17311</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>3/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>WASHINGTON  ?   It?s   or   time for Republica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17339</td>\n",
       "      <td>Jim Rutenberg</td>\n",
       "      <td>5/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>For Megyn Kelly, the shift from Fox News to NB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id               author        date  year month         topic  \\\n",
       "0  17307       Marlise Simons   1/01/2017  2017     1  architecture   \n",
       "1  17292          Andy Newman  31/12/2016  2016    12           art   \n",
       "2  17298  Emma G. Fitzsimmons   2/01/2017  2017     1      business   \n",
       "3  17311           Carl Hulse   3/01/2017  2017     1      business   \n",
       "4  17339        Jim Rutenberg   5/01/2017  2017     1      business   \n",
       "\n",
       "                                             article  \n",
       "0  PARIS  ?   When the Islamic State was about to...  \n",
       "1  Angels are everywhere in the Mu?iz family?s ap...  \n",
       "2  Finally. The Second Avenue subway opened in Ne...  \n",
       "3  WASHINGTON  ?   It?s   or   time for Republica...  \n",
       "4  For Megyn Kelly, the shift from Fox News to NB...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %pip install pandas\n",
    "import pandas as pd\n",
    "# %pip install chardet\n",
    "import chardet\n",
    "\n",
    "# Detect the encoding of the file\n",
    "rawdata = open('news_dataset.csv', 'rb').read()\n",
    "result = chardet.detect(rawdata)\n",
    "encoding = result['encoding']\n",
    "\n",
    "data = pd.read_csv('news_dataset.csv', encoding=encoding)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db085701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   id       1000 non-null   int64 \n",
      " 1   author   994 non-null    object\n",
      " 2   date     1000 non-null   object\n",
      " 3   year     1000 non-null   object\n",
      " 4   month    1000 non-null   object\n",
      " 5   topic    1000 non-null   object\n",
      " 6   article  1000 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 54.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33c30d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         1000\n",
       "author      994\n",
       "date       1000\n",
       "year       1000\n",
       "month      1000\n",
       "topic      1000\n",
       "article    1000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75f3592e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>topic</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17307</td>\n",
       "      <td>architecture</td>\n",
       "      <td>PARIS  ?   When the Islamic State was about to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17292</td>\n",
       "      <td>art</td>\n",
       "      <td>Angels are everywhere in the Mu?iz family?s ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17298</td>\n",
       "      <td>business</td>\n",
       "      <td>Finally. The Second Avenue subway opened in Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17311</td>\n",
       "      <td>business</td>\n",
       "      <td>WASHINGTON  ?   It?s   or   time for Republica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17339</td>\n",
       "      <td>business</td>\n",
       "      <td>For Megyn Kelly, the shift from Fox News to NB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>18460</td>\n",
       "      <td>accidents</td>\n",
       "      <td>HONG KONG  ?   Hundreds of pilot whales that s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>18461</td>\n",
       "      <td>sports</td>\n",
       "      <td>NICE, France  ?     Riv?re accepts the complim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>18462</td>\n",
       "      <td>business</td>\n",
       "      <td>FRANKFURT  ?   Germans who never really warmed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>18463</td>\n",
       "      <td>sports</td>\n",
       "      <td>Charles Oakley has strong feelings about compe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>18465</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>Hans Rosling, a Swedish doctor who transformed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         topic                                            article\n",
       "0    17307  architecture  PARIS  ?   When the Islamic State was about to...\n",
       "1    17292           art  Angels are everywhere in the Mu?iz family?s ap...\n",
       "2    17298      business  Finally. The Second Avenue subway opened in Ne...\n",
       "3    17311      business  WASHINGTON  ?   It?s   or   time for Republica...\n",
       "4    17339      business  For Megyn Kelly, the shift from Fox News to NB...\n",
       "..     ...           ...                                                ...\n",
       "995  18460     accidents  HONG KONG  ?   Hundreds of pilot whales that s...\n",
       "996  18461        sports  NICE, France  ?     Riv?re accepts the complim...\n",
       "997  18462      business  FRANKFURT  ?   Germans who never really warmed...\n",
       "998  18463        sports  Charles Oakley has strong feelings about compe...\n",
       "999  18465     lifestyle  Hans Rosling, a Swedish doctor who transformed...\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only id, topic, article\n",
    "data = data[['id', 'topic', 'article']]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa8d47b",
   "metadata": {},
   "source": [
    "### Coreference Resolution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9624f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cython==0.29 in /Users/wzx/anaconda3/envs/nlp/lib/python3.8/site-packages (0.29)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# coreference resolution\n",
    "# nerualcoref requires cython==0.29 and python 3.8\n",
    "import spacy\n",
    "%pip install cython==0.29\n",
    "# !git clone https://github.com/huggingface/neuralcoref.git\n",
    "# execute command after entering the directory\n",
    "# %cd neuralcoref \n",
    "# !pip install -r requirements.txt \n",
    "# !pip install -e .\n",
    "# !python -m spacy download en_core_web_sm\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# load NeuralCoref and add it to the pipe of SpaCy's model\n",
    "import neuralcoref\n",
    "coref = neuralcoref.NeuralCoref(nlp.vocab)\n",
    "nlp.add_pipe(coref, name='neuralcoref')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17456ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve coreference in an article\n",
    "# There should be no pronouns after this operation\n",
    "def resolve_coref(article):\n",
    "    return nlp(article)._.coref_resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f891d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>topic</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17307</td>\n",
       "      <td>architecture</td>\n",
       "      <td>PARIS     When the Islamic State was about to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17292</td>\n",
       "      <td>art</td>\n",
       "      <td>Angels are everywhere in the Muiz familys apar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17298</td>\n",
       "      <td>business</td>\n",
       "      <td>Finally. The Second Avenue subway opened in Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17311</td>\n",
       "      <td>business</td>\n",
       "      <td>WASHINGTON     Its   or   time for Republicans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17339</td>\n",
       "      <td>business</td>\n",
       "      <td>For Megyn Kelly, the shift from Fox News to NB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>18460</td>\n",
       "      <td>accidents</td>\n",
       "      <td>HONG KONG     Hundreds of pilot whales that sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>18461</td>\n",
       "      <td>sports</td>\n",
       "      <td>NICE, France       Rivre accepts the complimen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>18462</td>\n",
       "      <td>business</td>\n",
       "      <td>FRANKFURT     Germans who never really warmed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>18463</td>\n",
       "      <td>sports</td>\n",
       "      <td>Charles Oakley has strong feelings about compe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>18465</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>Hans Rosling, a Swedish doctor who transformed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         topic                                            article\n",
       "0    17307  architecture  PARIS     When the Islamic State was about to ...\n",
       "1    17292           art  Angels are everywhere in the Muiz familys apar...\n",
       "2    17298      business  Finally. The Second Avenue subway opened in Ne...\n",
       "3    17311      business  WASHINGTON     Its   or   time for Republicans...\n",
       "4    17339      business  For Megyn Kelly, the shift from Fox News to NB...\n",
       "..     ...           ...                                                ...\n",
       "995  18460     accidents  HONG KONG     Hundreds of pilot whales that sw...\n",
       "996  18461        sports  NICE, France       Rivre accepts the complimen...\n",
       "997  18462      business  FRANKFURT     Germans who never really warmed ...\n",
       "998  18463        sports  Charles Oakley has strong feelings about compe...\n",
       "999  18465     lifestyle  Hans Rosling, a Swedish doctor who transformed...\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace all '?' from article with empty string\n",
    "data['article'] = data['article'].str.replace('?', '')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c69f6261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Who is the vice chairman of Samsung?', 17574) ('Jay Y. Lee', 24)\n",
      "('Who was the President during the conflict?', 17311) ('George W. Bush', 24)\n",
      "('Who is the Senator of Colorado?', 17311) ('Cory Gardner', 34)\n",
      "('What was the revolt's name in 2010?', 17311) ('Tea Party Revolt', 25)\n",
      "('When did Republicans get control back?', 17311) ('2010', 25)\n",
      "('Where is the senior Republican from?', 17311) ('Oklahoma', 7)\n",
      "('Who was the president during the Iraq War?', 17311) ('George W. Bush', 24)\n",
      "('What amount did Fox News offer?', 17339) ('20 Million', 26)\n",
      "('What show and program will Megyn Kelly host?', 17339) ('a daily daytime show and a Sunday newsmagazine program', 41)\n",
      "('What is Andrew Lack adding?', 17339) ('journalist schooled in the preferences and worldviews of the conservative Americans who helped elect Mr Trump', 11)\n",
      "('When is Donald Trump's inauguration?', 17339) ('Jan. 20', 2)\n",
      "('Who is an executive chairman of 21st Century Fox?', 17339) ('Rupert Murdoch', 15)\n",
      "('Is Douglas Brunt a novelist?', 17339) ('a novelist', 24)\n",
      "('Which city and Which Province was the shooting?', 17344) ('Panzhihua city, Sichuan Province', 2)\n",
      "('Who was embarrassed by the violence?', 17344) ('Xi Jinping', 4)\n",
      "('Chen Zhongshu is the head of what?', 17344) ('Panzhihua Land and Resources Bureau,', 6)\n",
      "('The shooting happened where?', 17344) ('a exhibition center', 2)\n",
      "('Which year did Zhang Yan start working there?', 17344) ('2006', 11)\n",
      "('Where is Panzhihua, which Province?', 17344) ('Sichuan Province', 2)\n",
      "('What kind of city is Panzhihua?', 17344) ('industrial city', 2)\n",
      "('What news app did Apple remove from its app store by the request of Chinese authorities?', 17368) ('The New York Times', 6)\n",
      "('What kind of job did Hans Rosling do?', 18465) ('doctor', 0)\n",
      "('Where did Hans Rosling die?', 18465) ('Uppsala, Sweden', 0)\n",
      "('When did Hans Rosling die?', 18465) ('Tuesday', 0)\n",
      "('How old was Hans Rosling when he died?', 18465) ('68', 0)\n",
      "('Is Hans Rosling still alive?', 18465) ('died on Tuesday in Uppsala, Sweden. He was 68', 0)\n",
      "('Where did Yves Ubelmann get a call from?', 17307) ('Syria', 0)\n",
      "('How old is Mr. Ubelmann?', 17307) ('36', 0)\n",
      "('Who did they get the permisson from for getting married?', 17292) ('her uncle, a judge', 0)\n",
      "('In which city did The Second Avenue subway open?', 17298) ('New York City', 0)\n",
      "('When was The Second Avenue first proposed?', 17298) ('1920s', 0)\n",
      "('When did Betsy Morris leave the 96th Street sation?', 17298) ('at noon', 0)\n",
      "('When was his work included in group shows?', 17285) ('1932 and 1934', 0)\n",
      "('How many shows did they do for Thierry Mugler in Paris?', 17308) ('five', 0)\n",
      "('When is Mr. Mulvaney's confirmation hearing is scheduled?', 17760) ('Jan. 24', 0)\n",
      "('What are the Knicks celebrating?', 18463) ('their 70th anniversary', 0)\n",
      "('Has Oakley been invited to any of the events?', 18463) ('No', 0)\n",
      "('How many seasons has Oakley played for the Knicks?', 18463) ('10', 0)\n",
      "('Did Dolan become the chairman of the Graden before Oakley's left?', 18463) ('No', 0)\n",
      "('What did a teammate urged Oakley to do?', 18463) ('to keep his voice down', 0)\n",
      "('Why did West Germany move gold abroad?', 18462) ('out of fear they would be seized by an invading Soviet army', 0)\n",
      "('How many gold bars had been transfered by plan according to Bundesbank's words?', 18462) ('$13 billion', 0)\n",
      "('When did the Belin Wall fall?', 18462) ('1989', 0)\n",
      "('What's the form of the only sold gold by Bundesbank??', 18462) ('commemorative coins', 0)\n",
      "('How many nuclear tests has North Korea conducted in the last decade?', 17287) ('five', 0)\n",
      "('How many ballistic missile tests in 2016 alone?', 17287) ('20', 0)\n",
      "('How far could a warhead of 1,100 to 1,300 pounds fly?', 17287) ('more than 7,400 miles', 0)\n",
      "('What test has North Korea complished in April?', 17287) ('successful ground test of an engine for an intercontinental ballistic missile', 0)\n",
      "('When did the UN Security Council impose new sanctiions against North Korea?', 17287) ('In November', 0)\n",
      "('Who is the leader of North Korea?', 17287) ('Kim', 0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get test questions from test_questions_answers.txt\n",
    "# Open the file in read mode ('r') using relative path\n",
    "# %cd ../../\n",
    "with open('test_questions_answers.txt', 'r') as file:\n",
    "    # Read the content of the file\n",
    "    test_questions = file.read()\n",
    "\n",
    "print(test_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897fabf8",
   "metadata": {},
   "source": [
    "### Handle questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93fe60e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Who is the vice chairman of Samsung?', 'Jay Y. Lee', '17574'], ['Who was the President during the conflict?', 'George W. Bush', '17311'], ['Who is the Senator of Colorado?', 'Cory Gardner', '17311'], [\"What was the revolt's name in 2010?\", 'Tea Party Revolt', '17311'], ['When did Republicans get control back?', '2010', '17311'], ['Where is the senior Republican from?', 'Oklahoma', '17311'], ['Who was the president during the Iraq War?', 'George W. Bush', '17311'], ['What amount did Fox News offer?', '20 Million', '17339'], ['What show and program will Megyn Kelly host?', 'a daily daytime show and a Sunday newsmagazine program', '17339'], ['What is Andrew Lack adding?', 'journalist schooled in the preferences and worldviews of the conservative Americans who helped elect Mr Trump', '17339'], [\"When is Donald Trump's inauguration?\", 'Jan. 20', '17339'], ['Who is an executive chairman of 21st Century Fox?', 'Rupert Murdoch', '17339'], ['Is Douglas Brunt a novelist?', 'a novelist', '17339'], ['Which city and Which Province was the shooting?', 'Panzhihua city, Sichuan Province', '17344'], ['Who was embarrassed by the violence?', 'Xi Jinping', '17344'], ['Chen Zhongshu is the head of what?', 'Panzhihua Land and Resources Bureau,', '17344'], ['The shooting happened where?', 'a exhibition center', '17344'], ['Which year did Zhang Yan start working there?', '2006', '17344'], ['Where is Panzhihua, which Province?', 'Sichuan Province', '17344'], ['What kind of city is Panzhihua?', 'industrial city', '17344'], ['What news app did Apple remove from its app store by the request of Chinese authorities?', 'The New York Times', '17368'], ['What kind of job did Hans Rosling do?', 'doctor', '18465'], ['Where did Hans Rosling die?', 'Uppsala, Sweden', '18465'], ['When did Hans Rosling die?', 'Tuesday', '18465'], ['How old was Hans Rosling when he died?', '68', '18465'], ['Is Hans Rosling still alive?', 'died on Tuesday in Uppsala, Sweden. He was 68', '18465'], ['Where did Yves Ubelmann get a call from?', 'Syria', '17307'], ['How old is Mr. Ubelmann?', '36', '17307'], ['Who did they get the permisson from for getting married?', 'her uncle, a judge', '17292'], ['In which city did The Second Avenue subway open?', 'New York City', '17298'], ['When was The Second Avenue first proposed?', '1920s', '17298'], ['When did Betsy Morris leave the 96th Street sation?', 'at noon', '17298'], ['When was his work included in group shows?', '1932 and 1934', '17285'], ['How many shows did they do for Thierry Mugler in Paris?', 'five', '17308'], [\"When is Mr. Mulvaney's confirmation hearing is scheduled?\", 'Jan. 24', '17760'], ['What are the Knicks celebrating?', 'their 70th anniversary', '18463'], ['Has Oakley been invited to any of the events?', 'No', '18463'], ['How many seasons has Oakley played for the Knicks?', '10', '18463'], [\"Did Dolan become the chairman of the Graden before Oakley's left?\", 'No', '18463'], ['What did a teammate urged Oakley to do?', 'to keep his voice down', '18463'], ['Why did West Germany move gold abroad?', 'out of fear they would be seized by an invading Soviet army', '18462'], [\"How many gold bars had been transfered by plan according to Bundesbank's words?\", '$13 billion', '18462'], ['When did the Belin Wall fall?', '1989', '18462'], [\"What's the form of the only sold gold by Bundesbank??\", 'commemorative coins', '18462'], ['How many nuclear tests has North Korea conducted in the last decade?', 'five', '17287'], ['How many ballistic missile tests in 2016 alone?', '20', '17287'], ['How far could a warhead of 1,100 to 1,300 pounds fly?', 'more than 7,400 miles', '17287'], ['What test has North Korea complished in April?', 'successful ground test of an engine for an intercontinental ballistic missile', '17287'], ['When did the UN Security Council impose new sanctiions against North Korea?', 'In November', '17287'], ['Who is the leader of North Korea?', 'Kim', '17287']]\n"
     ]
    }
   ],
   "source": [
    "def get_question_answer(records):\n",
    "    '''\n",
    "    To extract question, answer, and article_id from the sample txt file\n",
    "    '''\n",
    "    records = records.split('\\n')\n",
    "    qa_pairs = []\n",
    "    for record in records:\n",
    "        r = record.split(') (')\n",
    "        if len(r) == 2:  # Check if split operation produces two elements\n",
    "            end = r[0].find(\"',\")\n",
    "            # Extract question and answer\n",
    "            question = r[0][2 : end]\n",
    "            article_id = r[0][end+3:]\n",
    "            end = r[1].find(\"',\")\n",
    "            answer = r[1][1 : end]\n",
    "            qa_pairs.append([question, answer, article_id])\n",
    "    return qa_pairs\n",
    "\n",
    "question_answer = get_question_answer(test_questions)\n",
    "print(question_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ef95c2",
   "metadata": {},
   "source": [
    "### Prepare two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18473b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wzx/anaconda3/envs/nlp/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at bert-large-cased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers\n",
    "# %pip install torch\n",
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "# Load the QA model and tokenizer\n",
    "model_name1 = \"bert-large-cased-whole-word-masking-finetuned-squad\"\n",
    "model1 = BertForQuestionAnswering.from_pretrained(model_name1)\n",
    "tokenizer1 = BertTokenizer.from_pretrained(model_name1)\n",
    "\n",
    "model_name2 = \"distilbert-base-cased-distilled-squad\"\n",
    "model2 = AutoModelForQuestionAnswering.from_pretrained(model_name2)\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(model_name2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7ebc95",
   "metadata": {},
   "source": [
    "### Define similarity check function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "183c0ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cosine similarity between query and article\n",
    "# !pip install scikit-learn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "def get_similarity(query, article):\n",
    "    '''\n",
    "    Calculate the cosine similarity between query and article\n",
    "    '''\n",
    "    # Combine the query and article into a list\n",
    "    documents = [query, article]\n",
    "    # Fit and transform the documents\n",
    "    X = vectorizer.fit_transform(documents)\n",
    "    # Calculate the cosine similarity\n",
    "    cosine_sim = cosine_similarity(X[0:1], X[1:2])\n",
    "    return cosine_sim[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395593e0",
   "metadata": {},
   "source": [
    "### A function for picking the highest similarity sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bbeef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the sentence with the highest similarity score\n",
    "# !pip install nltk\n",
    "import nltk\n",
    "\n",
    "def get_best_sentence(query, article):\n",
    "    # Tokenize the article into sentences\n",
    "    sentences = nltk.sent_tokenize(article)\n",
    "    best_sentence = ''\n",
    "    best_score = 0\n",
    "    for sentence in sentences:\n",
    "        score = get_similarity(query, sentence)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_sentence = sentence\n",
    "\n",
    "    print('Best sentence:', best_sentence, 'Similarity Score:', best_score)\n",
    "    return best_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c27a939",
   "metadata": {},
   "source": [
    "### The 1st model to answer questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b16d95ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question1(query, article):\n",
    "    '''\n",
    "    Takes a `query` string and an `article` string (which contains the\n",
    "    answer), and identifies the words within the `article` that are the\n",
    "    answer. Prints them out.\n",
    "    '''\n",
    "    # Resolve coreference in the article\n",
    "    article = resolve_coref(article)\n",
    "    # Check if the article is too long\n",
    "    if len(article) > 512:\n",
    "        # get the best sentence from the article\n",
    "        best_sentence = get_best_sentence(query, article)\n",
    "        # use the best sentence\n",
    "        article = best_sentence\n",
    "\n",
    "    # Tokenize the query and article\n",
    "    input_ids = tokenizer1.encode(query, article)\n",
    "\n",
    "    # Report how long the input sequence is.\n",
    "    # print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n",
    "\n",
    "    # ======== Set Segment IDs ========\n",
    "    # Search the input_ids for the first instance of the `[SEP]` token.\n",
    "    sep_index = input_ids.index(tokenizer1.sep_token_id)\n",
    "\n",
    "    # The number of segment A tokens includes the [SEP] token istelf.\n",
    "    num_seg_a = sep_index + 1\n",
    "\n",
    "    # The remainder are segment B.\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "\n",
    "    # Construct the list of 0s and 1s.\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "\n",
    "    # There should be a segment_id for every input token.\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "\n",
    "    # Truncate the sequence if it's longer than the limit\n",
    "    max_length = 512\n",
    "    if len(input_ids) > max_length:\n",
    "        input_ids = input_ids[:max_length]\n",
    "        segment_ids = segment_ids[:max_length]\n",
    "        \n",
    "    # ======== Evaluate ========\n",
    "    # Run our example question through the model.\n",
    "    model_scores = model1(torch.tensor([input_ids]), # The tokens representing our input text.\n",
    "                                    token_type_ids=torch.tensor([segment_ids])) # The segment IDs to differentiate question from answer_text\n",
    "    start_scores = model_scores.start_logits\n",
    "    end_scores = model_scores.end_logits\n",
    "    \n",
    "    # ======== Reconstruct Answer ========\n",
    "    # Find the tokens with the highest `start` and `end` scores.\n",
    "    answer_start = torch.argmax(start_scores)\n",
    "    answer_end = torch.argmax(end_scores)\n",
    "    # get confidence score for this answer\n",
    "    start_score = start_scores[0][answer_start].item()\n",
    "    end_score = end_scores[0][answer_end].item()\n",
    "    confidence_score = (start_score + end_score) / 2\n",
    "    print('Answer Confidence Score:', confidence_score)\n",
    "    # if confidence score is less than 0.5, return 'No answer'\n",
    "    if confidence_score < 0.5:\n",
    "        return 'No answer'\n",
    "\n",
    "    # Get the string versions of the input tokens.\n",
    "    tokens = tokenizer1.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "    # Start with the first token.\n",
    "    answer = tokens[answer_start]\n",
    "\n",
    "    # Select the remaining answer tokens and join them with whitespace.\n",
    "    for i in range(answer_start + 1, answer_end + 1):\n",
    "        \n",
    "        # If it's a subword token, then recombine it with the previous token.\n",
    "        if tokens[i][0:2] == '##':\n",
    "            answer += tokens[i][2:]\n",
    "        \n",
    "        # Otherwise, add a space then the token.\n",
    "        else:\n",
    "            answer += ' ' + tokens[i]\n",
    "    #regulate the answer that is a name \n",
    "    answer = answer.replace(\" .\", \".\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aced738a",
   "metadata": {},
   "source": [
    "### The 2nd model to answer questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0058eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question2(query, article):\n",
    "    '''\n",
    "    Takes a `query` string and an `article` string (which contains the\n",
    "    answer), and identifies the words within the `article` that are the\n",
    "    answer. Prints them out.\n",
    "    '''\n",
    "    # Resolve coreference in the article\n",
    "    article = resolve_coref(article)\n",
    "    # Check if the article is too long\n",
    "    if len(article) > 512:\n",
    "        # get the best sentence from the article\n",
    "        best_sentence = get_best_sentence(query, article)\n",
    "        # use the best sentence\n",
    "        article = best_sentence\n",
    "        \n",
    "    # Encode the question and article using the tokenizer\n",
    "    inputs = tokenizer2.encode_plus(query, article, return_tensors='pt', max_length=1024, truncation=True, truncation_strategy='only_second')\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "\n",
    "    # Pass the encoded input through the QA model\n",
    "    outputs = model2(input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "    start_logits = outputs.start_logits\n",
    "    end_logits = outputs.end_logits\n",
    "\n",
    "    # Decode the predicted start and end positions to get the answer\n",
    "    start_index = torch.argmax(start_logits)\n",
    "    end_index = torch.argmax(end_logits) + 1\n",
    "    # get confidence score for this answer\n",
    "    start_score = start_logits[0][start_index].item()\n",
    "    end_score = end_logits[0][end_index].item()\n",
    "    confidence_score = (start_score + end_score) / 2\n",
    "    print('Answer Confidence Score:', confidence_score)\n",
    "    # if confidence score is less than 0.5, return 'No answer'\n",
    "    if confidence_score < 0.5:\n",
    "        return 'No answer'\n",
    "\n",
    "    # Skip over any tokens before the start position or after the end position\n",
    "    for j, token_id in enumerate(input_ids[0]):\n",
    "        if j < start_index or j >= end_index:\n",
    "            input_ids[0][j] = tokenizer2.pad_token_id\n",
    "\n",
    "    # Decode the answer from the corresponding tokens\n",
    "    answer_tokens = input_ids[0][start_index:end_index]\n",
    "    answer = tokenizer2.decode(answer_tokens)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533728e5",
   "metadata": {},
   "source": [
    "### Loop and answer all prepared questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e15c648a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  Who is the vice chairman of Samsung?\n",
      "Sample Answer:  Jay Y. Lee\n",
      "Article Id: 17574 , Similarity Score: 0.35718566250951606\n",
      "Best sentence: Mr. Lee effectively runs Samsung, South Koreas largest conglomerate Mr. Lee is the son of SEOUL, South Korea     A special prosecutor investigating the corruption scandal that led to President Park  s impeachment chairman, Lee   who has been incapacitated with health problems. Similarity Score: 0.25847279483314756\n",
      "Answer Confidence Score: 4.599022626876831\n",
      "Answer: \"Mr. Lee\"\n",
      "----------------------------------------------\n",
      "Question:  Who was the President during the conflict?\n",
      "Sample Answer:  George W. Bush\n",
      "Article Id: 17311 , Similarity Score: 0.2874696945621706\n",
      "Best sentence: This isnt the same style of Republican majority pushed from power after being routed in the 2006 midterm elections after the public backlash to the administration of President George W. Bush and his handling of the war in Iraq. Similarity Score: 0.2933823911756418\n",
      "Answer Confidence Score: 9.57399606704712\n",
      "Answer: \"George W. Bush\"\n",
      "----------------------------------------------\n",
      "Question:  Who is the Senator of Colorado?\n",
      "Sample Answer:  Cory Gardner\n",
      "Article Id: 17311 , Similarity Score: 0.29853901255137527\n",
      "Best sentence: Republicans who have shied from the responsibility of government will now be called upon to support increases in the debt limit, approve annual budgets, endorse spending bills and back other   measures that Republicans who have shied from the responsibility of government formerly left to the Democrats and some of Republicans who have shied from the responsibility of government more compromising colleagues. Similarity Score: 0.2672923520844265\n",
      "Answer Confidence Score: 0.536247193813324\n",
      "Answer: \"[CLS]\"\n",
      "----------------------------------------------\n",
      "Question:  What was the revolt's name in 2010?\n",
      "Sample Answer:  Tea Party Revolt\n",
      "Article Id: 17311 , Similarity Score: 0.22136836025700324\n",
      "Best sentence: Republicans must also maneuver while facing slightly expanded Democratic minorities in the House and Senate, in a climate that is, in many respects, even more hostile than it was before the November elections. Similarity Score: 0.22478122925498784\n",
      "Answer Confidence Score: -0.18537965416908264\n",
      "Answer: \"No answer\"\n",
      "----------------------------------------------\n",
      "Question:  When did Republicans get control back?\n",
      "Sample Answer:  2010\n",
      "Article Id: 17311 , Similarity Score: 0.07651541872732139\n",
      "Best sentence: Republicans have won Republicans chance. Similarity Score: 0.19248422515864902\n",
      "Answer Confidence Score: 1.7631624937057495\n",
      "Answer: \"Republicans have won Republicans chance\"\n",
      "----------------------------------------------\n",
      "Question:  Where is the senior Republican from?\n",
      "Sample Answer:  Oklahoma\n",
      "Article Id: 17311 , Similarity Score: 0.22615776477498262\n",
      "Best sentence: When you have both houses and the presidency, there is no acceptable excuse for not passing major legislation, said Representative Tom Cole, a senior Republican from Oklahoma. Similarity Score: 0.27768042691247413\n",
      "Answer Confidence Score: 8.809242248535156\n",
      "Answer: \"Oklahoma\"\n",
      "----------------------------------------------\n",
      "Question:  Who was the president during the Iraq War?\n",
      "Sample Answer:  George W. Bush\n",
      "Article Id: 17311 , Similarity Score: 0.29183253280672666\n",
      "Best sentence: This isnt the same style of Republican majority pushed from power after being routed in the 2006 midterm elections after the public backlash to the administration of President George W. Bush and his handling of the war in Iraq. Similarity Score: 0.3495364600251307\n",
      "Answer Confidence Score: 10.199247360229492\n",
      "Answer: \"George W. Bush\"\n",
      "----------------------------------------------\n",
      "Question:  What amount did Fox News offer?\n",
      "Sample Answer:  20 Million\n",
      "Article Id: 17339 , Similarity Score: 0.09558971655444032\n",
      "Best sentence: Fox News rivals who sought to hire Ms. Kelly away, including Fox News, had indicated that Fox News rivals who sought to hire Ms. Kelly away, including NBC News could not match the $20 million offer from Fox, the cable news leader for the last 15 years running. Similarity Score: 0.26099219052490874\n",
      "Answer Confidence Score: 9.73075532913208\n",
      "Answer: \"$ 20 million\"\n",
      "----------------------------------------------\n",
      "Question:  What show and program will Megyn Kelly host?\n",
      "Sample Answer:  a daily daytime show and a Sunday newsmagazine program\n",
      "Article Id: 17339 , Similarity Score: 0.14561158615427336\n",
      "Best sentence: For Megyn Kelly, the shift from Fox News to NBC     where Megyn Kelly will host a daily daytime show and a Sunday newsmagazine program     will be a test of whether Megyn Kelly can connect with a broader audience in a different format and reach another level of television stardom. Similarity Score: 0.44712092903976663\n",
      "Answer Confidence Score: 6.706936359405518\n",
      "Answer: \"daily daytime show and a Sunday newsmagazine program\"\n",
      "----------------------------------------------\n",
      "Question:  What is Andrew Lack adding?\n",
      "Sample Answer:  journalist schooled in the preferences and worldviews of the conservative Americans who helped elect Mr Trump\n",
      "Article Id: 17339 , Similarity Score: 0.04211021827420341\n",
      "Best sentence: Lack career. Similarity Score: 0.19431434016858148\n",
      "Answer Confidence Score: 6.8211376667022705\n",
      "Answer: \"career\"\n",
      "----------------------------------------------\n",
      "Question:  When is Donald Trump's inauguration?\n",
      "Sample Answer:  Jan. 20\n",
      "Article Id: 17339 , Similarity Score: 0.031716563849258084\n",
      "Best sentence: And it comes as all news organizations gird for a new era of media coverage that arrives Jan. 20 with the inauguration of Donald J. Trump. Similarity Score: 0.16350800730668763\n",
      "Answer Confidence Score: 10.363226890563965\n",
      "Answer: \"Jan. 20\"\n",
      "----------------------------------------------\n",
      "Question:  Who is an executive chairman of 21st Century Fox?\n",
      "Sample Answer:  Rupert Murdoch\n",
      "Article Id: 17339 , Similarity Score: 0.15554542808422003\n",
      "Best sentence: Despite having made a generous offer to Ms. Kelly, Rupert Murdoch, an executive chairman of 21st Century Fox, whose   negotiation tactics are legendary, offered a supportive statement about Ms. Kellys decision to leave. Similarity Score: 0.2679793735980956\n",
      "Answer Confidence Score: 10.875818252563477\n",
      "Answer: \"Rupert Murdoch\"\n",
      "----------------------------------------------\n",
      "Question:  Is Douglas Brunt a novelist?\n",
      "Sample Answer:  a novelist\n",
      "Article Id: 17339 , Similarity Score: 0.030451199585256702\n",
      "Best sentence: The thing about this that is challenging but exciting as hell is that we love making new shows, Mr. Similarity Score: 0.117923684456103\n",
      "Answer Confidence Score: -0.5455535054206848\n",
      "Answer: \"No answer\"\n",
      "----------------------------------------------\n",
      "Question:  Which city and Which Province was the shooting?\n",
      "Sample Answer:  Panzhihua city, Sichuan Province\n",
      "Article Id: 17344 , Similarity Score: 0.2789970862583562\n",
      "Best sentence: So rumors of the shooting in Panzhihua, an industrial city in Sichuan Province, rippled quickly across the Chinese internet even before the local authorities confirmed the news. Similarity Score: 0.22246642401260774\n",
      "Answer Confidence Score: 8.900914192199707\n",
      "Answer: \"Sichuan\"\n",
      "----------------------------------------------\n",
      "Question:  Who was embarrassed by the violence?\n",
      "Sample Answer:  Xi Jinping\n",
      "Article Id: 17344 , Similarity Score: 0.26523248323622695\n",
      "Best sentence: But the violence in this isolated site was nonetheless an embarrassing breach of the efforts by Chinas president, Xi Jinping, to remake officialdom into a clean, impeccably disciplined bureaucracy. Similarity Score: 0.24488795959575482\n",
      "Answer Confidence Score: 8.45640230178833\n",
      "Answer: \"Xi Jinping\"\n",
      "----------------------------------------------\n",
      "Question:  Chen Zhongshu is the head of what?\n",
      "Sample Answer:  Panzhihua Land and Resources Bureau,\n",
      "Article Id: 17344 , Similarity Score: 0.28429446676677056\n",
      "Best sentence: But the brief initial report in the state media sketched a scene of the head of the Panzhihua Land and Resources Bureau, Chen Zhongshu, bursting into a meeting at an exhibition center and opening fire on officials there. Similarity Score: 0.3357365790643536\n",
      "Answer Confidence Score: 10.454635620117188\n",
      "Answer: \"Panzhihua Land and Resources Bureau\"\n",
      "----------------------------------------------\n",
      "Question:  The shooting happened where?\n",
      "Sample Answer:  a exhibition center\n",
      "Article Id: 17344 , Similarity Score: 0.2838354715635588\n",
      "Best sentence: The suspect in the shooting, Mr. Chen, was found dead in the exhibition center. Similarity Score: 0.28244678220628466\n",
      "Answer Confidence Score: 8.060036420822144\n",
      "Answer: \"exhibition center\"\n",
      "----------------------------------------------\n",
      "Question:  Which year did Zhang Yan start working there?\n",
      "Sample Answer:  2006\n",
      "Article Id: 17344 , Similarity Score: 0.03759486811566775\n",
      "Best sentence: Mr. Zhang, the party secretary, has worked in Panzhihua since 2006, and the mayor, Mr. Li, has worked there since last year, according to Chinese news reports. Similarity Score: 0.0998092590733763\n",
      "Answer Confidence Score: 9.33424186706543\n",
      "Answer: \"2006\"\n",
      "----------------------------------------------\n",
      "Question:  Where is Panzhihua, which Province?\n",
      "Sample Answer:  Sichuan Province\n",
      "Article Id: 17344 , Similarity Score: 0.043072461055570006\n",
      "Best sentence: Panzhihua was built as part of Maos plans to relocate factories deep inland, where they would be protected from a feared war. Similarity Score: 0.11298803279573305\n",
      "Answer Confidence Score: 3.57893705368042\n",
      "Answer: \"inland\"\n",
      "----------------------------------------------\n",
      "Question:  What kind of city is Panzhihua?\n",
      "Sample Answer:  industrial city\n",
      "Article Id: 17344 , Similarity Score: 0.09336764120465826\n",
      "Best sentence: So rumors of the shooting in Panzhihua, an industrial city in Sichuan Province, rippled quickly across the Chinese internet even before the local authorities confirmed the news. Similarity Score: 0.11365049453605691\n",
      "Answer Confidence Score: 9.53801679611206\n",
      "Answer: \"industrial\"\n",
      "----------------------------------------------\n",
      "Question:  What news app did Apple remove from its app store by the request of Chinese authorities?\n",
      "Sample Answer:  The New York Times\n",
      "Article Id: 17368 , Similarity Score: 0.3413842829995593\n",
      "Best sentence: Apple, complying with what Apple said was a request from Chinese authorities, removed news apps created by The New York Times from The New York Times app store in China late last month. Similarity Score: 0.39039153908672514\n",
      "Answer Confidence Score: 10.217055320739746\n",
      "Answer: \"The New York Times\"\n",
      "----------------------------------------------\n",
      "Question:  What kind of job did Hans Rosling do?\n",
      "Sample Answer:  doctor\n",
      "Article Id: 18465 , Similarity Score: 0.08450096910930717\n",
      "Best sentence: Dr. Rosling investigation of a paralytic disease called konzo in the Democratic Republic of Congo, which was determined to be caused by ingesting naturally occurring cyanide in cassava roots, earned Dr. Rosling a doctorate from Uppsala University. Similarity Score: 0.12236959990898792\n",
      "Answer Confidence Score: 5.8637778759002686\n",
      "Answer: \"Dr\"\n",
      "----------------------------------------------\n",
      "Question:  Where did Hans Rosling die?\n",
      "Sample Answer:  Uppsala, Sweden\n",
      "Article Id: 18465 , Similarity Score: 0.048495258477602374\n",
      "Best sentence: Dr. Rosling studied statistics and medicine at Uppsala University and public health at St. Johns Medical College in Bangalore, India, where Dr. Rosling received Dr. Rosling medical degree in 1976. Similarity Score: 0.15059329441769112\n",
      "Answer Confidence Score: 3.3373241424560547\n",
      "Answer: \"Bangalore , India\"\n",
      "----------------------------------------------\n",
      "Question:  When did Hans Rosling die?\n",
      "Sample Answer:  Tuesday\n",
      "Article Id: 18465 , Similarity Score: 0.045797697181893256\n",
      "Best sentence: Dr. Rosling was delivering on a pledge Dr. Rosling had made years earlier to Eduardo Mondlane, the founder of the Mozambican Liberation Front, to help provide health services when Mozambique became independent. Similarity Score: 0.12544176637326365\n",
      "Answer Confidence Score: -0.7963746935129166\n",
      "Answer: \"No answer\"\n",
      "----------------------------------------------\n",
      "Question:  How old was Hans Rosling when he died?\n",
      "Sample Answer:  68\n",
      "Article Id: 18465 , Similarity Score: 0.1402014418143718\n",
      "Best sentence: Dr. Rosling was a coffee roaster. Similarity Score: 0.1908740661302035\n",
      "Answer Confidence Score: 2.876689076423645\n",
      "Answer: \"Dr\"\n",
      "----------------------------------------------\n",
      "Question:  Is Hans Rosling still alive?\n",
      "Sample Answer:  died on Tuesday in Uppsala, Sweden. He was 68\n",
      "Article Id: 18465 , Similarity Score: 0.05931870390475712\n",
      "Best sentence: Even before   entered the lexicon, Dr. Rosling was echoing former Senator Daniel Patrick Moynihans maxim that everyone is entitled to Dr. Rosling own opinions but not to Dr. Rosling own facts. Similarity Score: 0.15587115556741182\n",
      "Answer Confidence Score: 0.6229000240564346\n",
      "Answer: \"Is Hans Rosling still alive\"\n",
      "----------------------------------------------\n",
      "Question:  Where did Yves Ubelmann get a call from?\n",
      "Sample Answer:  Syria\n",
      "Article Id: 17307 , Similarity Score: 0.04821464925885893\n",
      "Best sentence: PARIS     When the Islamic State was about to be driven out of the ancient city of Palmyra in March, Yves Ubelmann got a call from Syrias director of antiquities to come over in a hurry. Similarity Score: 0.1377185831824274\n",
      "Answer Confidence Score: 8.922820568084717\n",
      "Answer: \"Syrias director of antiquities\"\n",
      "----------------------------------------------\n",
      "Question:  How old is Mr. Ubelmann?\n",
      "Sample Answer:  36\n",
      "Article Id: 17307 , Similarity Score: 0.08394577071663864\n",
      "Best sentence: Palmyra was very difficult, Mr. Ubelmann said. Similarity Score: 0.20613696606828608\n",
      "Answer Confidence Score: -0.1597866714000702\n",
      "Answer: \"No answer\"\n",
      "----------------------------------------------\n",
      "Question:  Who did they get the permisson from for getting married?\n",
      "Sample Answer:  her uncle, a judge\n",
      "Article Id: 17292 , Similarity Score: 0.19064271778775546\n",
      "Best sentence: they did not respond to medication. Similarity Score: 0.15064018498706513\n",
      "Answer Confidence Score: 2.4157662391662598\n",
      "Answer: \"medication\"\n",
      "----------------------------------------------\n",
      "Question:  In which city did The Second Avenue subway open?\n",
      "Sample Answer:  New York City\n",
      "Article Id: 17298 , Similarity Score: 0.3550205687166691\n",
      "Best sentence: The Second Avenue subway opened in New York City on Sunday, with thousands of riders flooding into The Second Avenue subway polished stations to witness a piece of history nearly a century in the making. Similarity Score: 0.41113604788120617\n",
      "Answer Confidence Score: 10.065578937530518\n",
      "Answer: \"New York City\"\n",
      "----------------------------------------------\n",
      "Question:  When was The Second Avenue first proposed?\n",
      "Sample Answer:  1920s\n",
      "Article Id: 17298 , Similarity Score: 0.31523490828320005\n",
      "Best sentence: So the arrival of the   Second Avenue subway, which was first proposed in the 1920s, was a notable achievement for the   Metropolitan Transportation Authority, which runs the citys vast network of subways, buses and commuter railroads. Similarity Score: 0.41449096849870737\n",
      "Answer Confidence Score: 9.456826210021973\n",
      "Answer: \"1920s\"\n",
      "----------------------------------------------\n",
      "Question:  When did Betsy Morris leave the 96th Street sation?\n",
      "Sample Answer:  at noon\n",
      "Article Id: 17298 , Similarity Score: 0.224947882560698\n",
      "Best sentence: I was very choked up, Betsy Morris, 70, said as she rode the first train to leave the 96th Street station, at noon. Similarity Score: 0.326128268778914\n",
      "Answer Confidence Score: 8.645111322402954\n",
      "Answer: \"noon\"\n",
      "----------------------------------------------\n",
      "Question:  When was his work included in group shows?\n",
      "Sample Answer:  1932 and 1934\n",
      "Article Id: 17285 , Similarity Score: 0.23277993598356164\n",
      "Best sentence: In 1932 and again in 1934, he work was included in group shows at the Art Institute of Chicago that also featured Picasso, Matisse and Paul Klee. Similarity Score: 0.3404771650991819\n",
      "Answer Confidence Score: 7.9376678466796875\n",
      "Answer: \"1932 and again in 1934\"\n",
      "----------------------------------------------\n",
      "Question:  How many shows did they do for Thierry Mugler in Paris?\n",
      "Sample Answer:  five\n",
      "Article Id: 17308 , Similarity Score: 0.10575625514940801\n",
      "Best sentence: The night before the video, I didnt sleep at all, because Wed did five shows for Thierry Mugler in Paris. Similarity Score: 0.30803834549042\n",
      "Answer Confidence Score: 7.94809103012085\n",
      "Answer: \"five\"\n",
      "----------------------------------------------\n",
      "Question:  When is Mr. Mulvaney's confirmation hearing is scheduled?\n",
      "Sample Answer:  Jan. 24\n",
      "Article Id: 17760 , Similarity Score: 0.13007985200526295\n",
      "Best sentence: Mr. Mulvaney confirmation hearing before the Senate Budget Committee is scheduled for Jan. 24. Similarity Score: 0.4525165721133184\n",
      "Answer Confidence Score: 10.166244506835938\n",
      "Answer: \"Jan. 24\"\n",
      "----------------------------------------------\n",
      "Question:  What are the Knicks celebrating?\n",
      "Sample Answer:  their 70th anniversary\n",
      "Article Id: 18463 , Similarity Score: 0.31120211028289835\n",
      "Best sentence: This season, for example, The Knicks are celebrating The Knicks 70th anniversary, and Charles Oakley has not been invited to participate in any of the events. Similarity Score: 0.39510078534191984\n",
      "Answer Confidence Score: 9.708595275878906\n",
      "Answer: \"The Knicks 70th anniversary\"\n",
      "----------------------------------------------\n",
      "Question:  Has Oakley been invited to any of the events?\n",
      "Sample Answer:  No\n",
      "Article Id: 18463 , Similarity Score: 0.42378550460377007\n",
      "Best sentence: This season, for example, The Knicks are celebrating The Knicks 70th anniversary, and Charles Oakley has not been invited to participate in any of the events. Similarity Score: 0.5155600305501107\n",
      "Answer Confidence Score: 6.355990648269653\n",
      "Answer: \"not\"\n",
      "----------------------------------------------\n",
      "Question:  How many seasons has Oakley played for the Knicks?\n",
      "Sample Answer:  10\n",
      "Article Id: 18463 , Similarity Score: 0.3481444466136765\n",
      "Best sentence: Charles Oakley played for the Knicks for 10 seasons and through much of the 1990s, when the Knicks were a tough, competitive team and Oakleys determined physical presence near the basket epitomized everything the Knicks were about. Similarity Score: 0.3875805374667165\n",
      "Answer Confidence Score: 8.484732627868652\n",
      "Answer: \"10\"\n",
      "----------------------------------------------\n",
      "Question:  Did Dolan become the chairman of the Graden before Oakley's left?\n",
      "Sample Answer:  No\n",
      "Article Id: 18463 , Similarity Score: 0.42759347370881945\n",
      "Best sentence: Dolan did not become the chairman of the Garden until Charles Oakley had already left the Knicks. Similarity Score: 0.6156104057466073\n",
      "Answer Confidence Score: 6.408429384231567\n",
      "Answer: \"Dolan did not\"\n",
      "----------------------------------------------\n",
      "Question:  What did a teammate urged Oakley to do?\n",
      "Sample Answer:  to keep his voice down\n",
      "Article Id: 18463 , Similarity Score: 0.13994036003206548\n",
      "Best sentence: a former teammate near the court, Charles Oakley said, apprehensively urged Charles Oakley to keep Charles Oakley voice down. Similarity Score: 0.2761605428370851\n",
      "Answer Confidence Score: 8.083657503128052\n",
      "Answer: \"keep Charles Oakley voice down\"\n",
      "----------------------------------------------\n",
      "Question:  Why did West Germany move gold abroad?\n",
      "Sample Answer:  out of fear they would be seized by an invading Soviet army\n",
      "Article Id: 18462 , Similarity Score: 0.10630861568370387\n",
      "Best sentence: During the Cold War, when West Germany was on the front lines of   conflict, West Germany moved large amounts of West Germany reserves abroad out of fear fear would be seized by an invading Soviet army. Similarity Score: 0.21634002319916606\n",
      "Answer Confidence Score: 8.503471374511719\n",
      "Answer: \"out of fear fear would be seized by an invading Soviet army\"\n",
      "----------------------------------------------\n",
      "Question:  How many gold bars had been transfered by plan according to Bundesbank's words?\n",
      "Sample Answer:  $13 billion\n",
      "Article Id: 18462 , Similarity Score: 0.1538462134222321\n",
      "Best sentence: the Bundesbank has been secretive about how the Bundesbank moved the gold, to discourage anyone who might try to steal the Bundesbank. Similarity Score: 0.2137144737277952\n",
      "Answer Confidence Score: -1.1752006113529205\n",
      "Answer: \"No answer\"\n",
      "----------------------------------------------\n",
      "Question:  When did the Belin Wall fall?\n",
      "Sample Answer:  1989\n",
      "Article Id: 18462 , Similarity Score: 0.1665620703775355\n",
      "Best sentence: Even after the Berlin Wall fell in 1989, the gold stayed overseas. Similarity Score: 0.1997638141375695\n",
      "Answer Confidence Score: 8.448993921279907\n",
      "Answer: \"1989\"\n",
      "----------------------------------------------\n",
      "Question:  What's the form of the only sold gold by Bundesbank??\n",
      "Sample Answer:  commemorative coins\n",
      "Article Id: 18462 , Similarity Score: 0.4889701283753193\n",
      "Best sentence: So far, the gold the Bundesbank has been in the form of commemorative coins. Similarity Score: 0.4841663540264622\n",
      "Answer Confidence Score: 9.740064144134521\n",
      "Answer: \"commemorative coins\"\n",
      "----------------------------------------------\n",
      "Question:  How many nuclear tests has North Korea conducted in the last decade?\n",
      "Sample Answer:  five\n",
      "Article Id: 17287 , Similarity Score: 0.34981865180024385\n",
      "Best sentence: Although South Korea has conducted five nuclear tests in the last decade and more than 20 ballistic missile tests in 2016 alone, and although South Korea habitually threatens to attack the United States with nuclear weapons, South Korea has never   an intercontinental ballistic missile, or ICBM. Similarity Score: 0.3797787815726839\n",
      "Answer Confidence Score: 7.549510478973389\n",
      "Answer: \"five\"\n",
      "----------------------------------------------\n",
      "Question:  How many ballistic missile tests in 2016 alone?\n",
      "Sample Answer:  20\n",
      "Article Id: 17287 , Similarity Score: 0.17047404629158527\n",
      "Best sentence: Although South Korea has conducted five nuclear tests in the last decade and more than 20 ballistic missile tests in 2016 alone, and although South Korea habitually threatens to attack the United States with nuclear weapons, South Korea has never   an intercontinental ballistic missile, or ICBM. Similarity Score: 0.2753293668209869\n",
      "Answer Confidence Score: 8.550378322601318\n",
      "Answer: \"more than 20\"\n",
      "----------------------------------------------\n",
      "Question:  How far could a warhead of 1,100 to 1,300 pounds fly?\n",
      "Sample Answer:  more than 7,400 miles\n",
      "Article Id: 17287 , Similarity Score: 0.13518061765763792\n",
      "Best sentence: After the Norths satellite launch in February, South Korean defense officials said the Unha rocket used in the Norths satellite launch in February, if successfully reconfigured as a missile, could fly more than 7, 400 miles with a warhead of 1, 100 to 1, 300 pounds     far enough to reach most of the United States. Similarity Score: 0.2772773757563899\n",
      "Answer Confidence Score: 7.495723485946655\n",
      "Answer: \"7 , 400 miles\"\n",
      "----------------------------------------------\n",
      "Question:  What test has North Korea complished in April?\n",
      "Sample Answer:  successful ground test of an engine for an intercontinental ballistic missile\n",
      "Article Id: 17287 , Similarity Score: 0.22917746180348283\n",
      "Best sentence: In April, South Korea reported the successful ground test of an engine for an intercontinental ballistic missile. Similarity Score: 0.19993965835322458\n",
      "Answer Confidence Score: 7.520449876785278\n",
      "Answer: \"an engine for an intercontinental ballistic missile\"\n",
      "----------------------------------------------\n",
      "Question:  When did the UN Security Council impose new sanctiions against North Korea?\n",
      "Sample Answer:  In November\n",
      "Article Id: 17287 , Similarity Score: 0.205599983776415\n",
      "Best sentence: In November, the United Nations Security Council imposed new  sanctions against South Korea. Similarity Score: 0.3189156497867721\n",
      "Answer Confidence Score: 9.008477687835693\n",
      "Answer: \"November\"\n",
      "----------------------------------------------\n",
      "Question:  Who is the leader of North Korea?\n",
      "Sample Answer:  Kim\n",
      "Article Id: 17287 , Similarity Score: 0.3335611295293365\n",
      "Best sentence: We need to take note of the fact that this is the first New Years speech where Kim   mentioned an intercontinental ballistic missile, Cheong   a senior research fellow at the Sejong Institute in South Korea said. Similarity Score: 0.22879457947215806\n",
      "Answer Confidence Score: 7.875328302383423\n",
      "Answer: \"Kim\"\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# search for the answer in the specific article\n",
    "for qa in question_answer:\n",
    "    question = qa[0]\n",
    "    sample_answer = qa[1]\n",
    "    article_id = qa[2]\n",
    "    print(\"Question: \", question)\n",
    "    print(\"Sample Answer: \", sample_answer)\n",
    "    article = data[data['id'] == int(article_id)]['article'].values[0]\n",
    "    similarity = get_similarity(question, article)\n",
    "    print('Article Id:', article_id, ', Similarity Score:', similarity)\n",
    "\n",
    "    print('Answer: \"' + answer_question1(question, article) + '\"')\n",
    "    # print('Answer: \"' + answer_question2(question, article) + '\"')\n",
    "    print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9130487",
   "metadata": {},
   "source": [
    "### Evaluation metrics (Exact match & F1 score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7342c0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Load a pre-trained QA model and tokenizer\n",
    "# qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "# qa_pipeline = pipeline(\"question-answering\", model=\"bert-large-cased-whole-word-masking-finetuned-squad\")\n",
    "\n",
    "# Function to compute exact match\n",
    "def exact_match(prediction, expected_answer):\n",
    "    return int(any(prediction == w for w in expected_answer))\n",
    "\n",
    "# Function to compute F1 score\n",
    "def f1_score(prediction, expected_answer):\n",
    "    def compute_f1(a_gold, a_pred):\n",
    "        gold_tokens = a_gold.split()\n",
    "        pred_tokens = a_pred.split()\n",
    "        common = Counter(gold_tokens) & Counter(pred_tokens)\n",
    "        num_same = sum(common.values())\n",
    "        if num_same == 0:\n",
    "            return 0\n",
    "        precision = 1.0 * num_same / len(pred_tokens)\n",
    "        recall = 1.0 * num_same / len(gold_tokens)\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "        return f1\n",
    "\n",
    "    return max(compute_f1(w, prediction) for w in expected_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256745ab",
   "metadata": {},
   "source": [
    "### Show general scores by calculating the mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1ac6876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best sentence: Mr. Lee effectively runs Samsung, South Koreas largest conglomerate Mr. Lee is the son of SEOUL, South Korea     A special prosecutor investigating the corruption scandal that led to President Park  s impeachment chairman, Lee   who has been incapacitated with health problems. Similarity Score: 0.25847279483314756\n",
      "Answer Confidence Score: 4.599022626876831\n",
      "Best sentence: This isnt the same style of Republican majority pushed from power after being routed in the 2006 midterm elections after the public backlash to the administration of President George W. Bush and his handling of the war in Iraq. Similarity Score: 0.2933823911756418\n",
      "Answer Confidence Score: 9.57399606704712\n",
      "Best sentence: Republicans who have shied from the responsibility of government will now be called upon to support increases in the debt limit, approve annual budgets, endorse spending bills and back other   measures that Republicans who have shied from the responsibility of government formerly left to the Democrats and some of Republicans who have shied from the responsibility of government more compromising colleagues. Similarity Score: 0.2672923520844265\n",
      "Answer Confidence Score: 0.536247193813324\n",
      "Best sentence: Republicans must also maneuver while facing slightly expanded Democratic minorities in the House and Senate, in a climate that is, in many respects, even more hostile than it was before the November elections. Similarity Score: 0.22478122925498784\n",
      "Answer Confidence Score: -0.18537965416908264\n",
      "Best sentence: Republicans have won Republicans chance. Similarity Score: 0.19248422515864902\n",
      "Answer Confidence Score: 1.7631624937057495\n",
      "Best sentence: When you have both houses and the presidency, there is no acceptable excuse for not passing major legislation, said Representative Tom Cole, a senior Republican from Oklahoma. Similarity Score: 0.27768042691247413\n",
      "Answer Confidence Score: 8.809242248535156\n",
      "Best sentence: This isnt the same style of Republican majority pushed from power after being routed in the 2006 midterm elections after the public backlash to the administration of President George W. Bush and his handling of the war in Iraq. Similarity Score: 0.3495364600251307\n",
      "Answer Confidence Score: 10.199247360229492\n",
      "Best sentence: Fox News rivals who sought to hire Ms. Kelly away, including Fox News, had indicated that Fox News rivals who sought to hire Ms. Kelly away, including NBC News could not match the $20 million offer from Fox, the cable news leader for the last 15 years running. Similarity Score: 0.26099219052490874\n",
      "Answer Confidence Score: 9.73075532913208\n",
      "Best sentence: For Megyn Kelly, the shift from Fox News to NBC     where Megyn Kelly will host a daily daytime show and a Sunday newsmagazine program     will be a test of whether Megyn Kelly can connect with a broader audience in a different format and reach another level of television stardom. Similarity Score: 0.44712092903976663\n",
      "Answer Confidence Score: 6.706936359405518\n",
      "Best sentence: Lack career. Similarity Score: 0.19431434016858148\n",
      "Answer Confidence Score: 6.8211376667022705\n",
      "Best sentence: And it comes as all news organizations gird for a new era of media coverage that arrives Jan. 20 with the inauguration of Donald J. Trump. Similarity Score: 0.16350800730668763\n",
      "Answer Confidence Score: 10.363226890563965\n",
      "Best sentence: Despite having made a generous offer to Ms. Kelly, Rupert Murdoch, an executive chairman of 21st Century Fox, whose   negotiation tactics are legendary, offered a supportive statement about Ms. Kellys decision to leave. Similarity Score: 0.2679793735980956\n",
      "Answer Confidence Score: 10.875818252563477\n",
      "Best sentence: The thing about this that is challenging but exciting as hell is that we love making new shows, Mr. Similarity Score: 0.117923684456103\n",
      "Answer Confidence Score: -0.5455535054206848\n",
      "Best sentence: So rumors of the shooting in Panzhihua, an industrial city in Sichuan Province, rippled quickly across the Chinese internet even before the local authorities confirmed the news. Similarity Score: 0.22246642401260774\n",
      "Answer Confidence Score: 8.900914192199707\n",
      "Best sentence: But the violence in this isolated site was nonetheless an embarrassing breach of the efforts by Chinas president, Xi Jinping, to remake officialdom into a clean, impeccably disciplined bureaucracy. Similarity Score: 0.24488795959575482\n",
      "Answer Confidence Score: 8.45640230178833\n",
      "Best sentence: But the brief initial report in the state media sketched a scene of the head of the Panzhihua Land and Resources Bureau, Chen Zhongshu, bursting into a meeting at an exhibition center and opening fire on officials there. Similarity Score: 0.3357365790643536\n",
      "Answer Confidence Score: 10.454635620117188\n",
      "Best sentence: The suspect in the shooting, Mr. Chen, was found dead in the exhibition center. Similarity Score: 0.28244678220628466\n",
      "Answer Confidence Score: 8.060036420822144\n",
      "Best sentence: Mr. Zhang, the party secretary, has worked in Panzhihua since 2006, and the mayor, Mr. Li, has worked there since last year, according to Chinese news reports. Similarity Score: 0.0998092590733763\n",
      "Answer Confidence Score: 9.33424186706543\n",
      "Best sentence: Panzhihua was built as part of Maos plans to relocate factories deep inland, where they would be protected from a feared war. Similarity Score: 0.11298803279573305\n",
      "Answer Confidence Score: 3.57893705368042\n",
      "Best sentence: So rumors of the shooting in Panzhihua, an industrial city in Sichuan Province, rippled quickly across the Chinese internet even before the local authorities confirmed the news. Similarity Score: 0.11365049453605691\n",
      "Answer Confidence Score: 9.53801679611206\n",
      "Best sentence: Apple, complying with what Apple said was a request from Chinese authorities, removed news apps created by The New York Times from The New York Times app store in China late last month. Similarity Score: 0.39039153908672514\n",
      "Answer Confidence Score: 10.217055320739746\n",
      "Best sentence: Dr. Rosling investigation of a paralytic disease called konzo in the Democratic Republic of Congo, which was determined to be caused by ingesting naturally occurring cyanide in cassava roots, earned Dr. Rosling a doctorate from Uppsala University. Similarity Score: 0.12236959990898792\n",
      "Answer Confidence Score: 5.8637778759002686\n",
      "Best sentence: Dr. Rosling studied statistics and medicine at Uppsala University and public health at St. Johns Medical College in Bangalore, India, where Dr. Rosling received Dr. Rosling medical degree in 1976. Similarity Score: 0.15059329441769112\n",
      "Answer Confidence Score: 3.3373241424560547\n",
      "Best sentence: Dr. Rosling was delivering on a pledge Dr. Rosling had made years earlier to Eduardo Mondlane, the founder of the Mozambican Liberation Front, to help provide health services when Mozambique became independent. Similarity Score: 0.12544176637326365\n",
      "Answer Confidence Score: -0.7963746935129166\n",
      "Best sentence: Dr. Rosling was a coffee roaster. Similarity Score: 0.1908740661302035\n",
      "Answer Confidence Score: 2.876689076423645\n",
      "Best sentence: Even before   entered the lexicon, Dr. Rosling was echoing former Senator Daniel Patrick Moynihans maxim that everyone is entitled to Dr. Rosling own opinions but not to Dr. Rosling own facts. Similarity Score: 0.15587115556741182\n",
      "Answer Confidence Score: 0.6229000240564346\n",
      "Best sentence: PARIS     When the Islamic State was about to be driven out of the ancient city of Palmyra in March, Yves Ubelmann got a call from Syrias director of antiquities to come over in a hurry. Similarity Score: 0.1377185831824274\n",
      "Answer Confidence Score: 8.922820568084717\n",
      "Best sentence: Palmyra was very difficult, Mr. Ubelmann said. Similarity Score: 0.20613696606828608\n",
      "Answer Confidence Score: -0.1597866714000702\n",
      "Best sentence: they did not respond to medication. Similarity Score: 0.15064018498706513\n",
      "Answer Confidence Score: 2.4157662391662598\n",
      "Best sentence: The Second Avenue subway opened in New York City on Sunday, with thousands of riders flooding into The Second Avenue subway polished stations to witness a piece of history nearly a century in the making. Similarity Score: 0.41113604788120617\n",
      "Answer Confidence Score: 10.065578937530518\n",
      "Best sentence: So the arrival of the   Second Avenue subway, which was first proposed in the 1920s, was a notable achievement for the   Metropolitan Transportation Authority, which runs the citys vast network of subways, buses and commuter railroads. Similarity Score: 0.41449096849870737\n",
      "Answer Confidence Score: 9.456826210021973\n",
      "Best sentence: I was very choked up, Betsy Morris, 70, said as she rode the first train to leave the 96th Street station, at noon. Similarity Score: 0.326128268778914\n",
      "Answer Confidence Score: 8.645111322402954\n",
      "Best sentence: In 1932 and again in 1934, he work was included in group shows at the Art Institute of Chicago that also featured Picasso, Matisse and Paul Klee. Similarity Score: 0.3404771650991819\n",
      "Answer Confidence Score: 7.9376678466796875\n",
      "Best sentence: The night before the video, I didnt sleep at all, because Wed did five shows for Thierry Mugler in Paris. Similarity Score: 0.30803834549042\n",
      "Answer Confidence Score: 7.94809103012085\n",
      "Best sentence: Mr. Mulvaney confirmation hearing before the Senate Budget Committee is scheduled for Jan. 24. Similarity Score: 0.4525165721133184\n",
      "Answer Confidence Score: 10.166244506835938\n",
      "Best sentence: This season, for example, The Knicks are celebrating The Knicks 70th anniversary, and Charles Oakley has not been invited to participate in any of the events. Similarity Score: 0.39510078534191984\n",
      "Answer Confidence Score: 9.708595275878906\n",
      "Best sentence: This season, for example, The Knicks are celebrating The Knicks 70th anniversary, and Charles Oakley has not been invited to participate in any of the events. Similarity Score: 0.5155600305501107\n",
      "Answer Confidence Score: 6.355990648269653\n",
      "Best sentence: Charles Oakley played for the Knicks for 10 seasons and through much of the 1990s, when the Knicks were a tough, competitive team and Oakleys determined physical presence near the basket epitomized everything the Knicks were about. Similarity Score: 0.3875805374667165\n",
      "Answer Confidence Score: 8.484732627868652\n",
      "Best sentence: Dolan did not become the chairman of the Garden until Charles Oakley had already left the Knicks. Similarity Score: 0.6156104057466073\n",
      "Answer Confidence Score: 6.408429384231567\n",
      "Best sentence: a former teammate near the court, Charles Oakley said, apprehensively urged Charles Oakley to keep Charles Oakley voice down. Similarity Score: 0.2761605428370851\n",
      "Answer Confidence Score: 8.083657503128052\n",
      "Best sentence: During the Cold War, when West Germany was on the front lines of   conflict, West Germany moved large amounts of West Germany reserves abroad out of fear fear would be seized by an invading Soviet army. Similarity Score: 0.21634002319916606\n",
      "Answer Confidence Score: 8.503471374511719\n",
      "Best sentence: the Bundesbank has been secretive about how the Bundesbank moved the gold, to discourage anyone who might try to steal the Bundesbank. Similarity Score: 0.2137144737277952\n",
      "Answer Confidence Score: -1.1752006113529205\n",
      "Best sentence: Even after the Berlin Wall fell in 1989, the gold stayed overseas. Similarity Score: 0.1997638141375695\n",
      "Answer Confidence Score: 8.448993921279907\n",
      "Best sentence: So far, the gold the Bundesbank has been in the form of commemorative coins. Similarity Score: 0.4841663540264622\n",
      "Answer Confidence Score: 9.740064144134521\n",
      "Best sentence: Although South Korea has conducted five nuclear tests in the last decade and more than 20 ballistic missile tests in 2016 alone, and although South Korea habitually threatens to attack the United States with nuclear weapons, South Korea has never   an intercontinental ballistic missile, or ICBM. Similarity Score: 0.3797787815726839\n",
      "Answer Confidence Score: 7.549510478973389\n",
      "Best sentence: Although South Korea has conducted five nuclear tests in the last decade and more than 20 ballistic missile tests in 2016 alone, and although South Korea habitually threatens to attack the United States with nuclear weapons, South Korea has never   an intercontinental ballistic missile, or ICBM. Similarity Score: 0.2753293668209869\n",
      "Answer Confidence Score: 8.550378322601318\n",
      "Best sentence: After the Norths satellite launch in February, South Korean defense officials said the Unha rocket used in the Norths satellite launch in February, if successfully reconfigured as a missile, could fly more than 7, 400 miles with a warhead of 1, 100 to 1, 300 pounds     far enough to reach most of the United States. Similarity Score: 0.2772773757563899\n",
      "Answer Confidence Score: 7.495723485946655\n",
      "Best sentence: In April, South Korea reported the successful ground test of an engine for an intercontinental ballistic missile. Similarity Score: 0.19993965835322458\n",
      "Answer Confidence Score: 7.520449876785278\n",
      "Best sentence: In November, the United Nations Security Council imposed new  sanctions against South Korea. Similarity Score: 0.3189156497867721\n",
      "Answer Confidence Score: 9.008477687835693\n",
      "Best sentence: We need to take note of the fact that this is the first New Years speech where Kim   mentioned an intercontinental ballistic missile, Cheong   a senior research fellow at the Sejong Institute in South Korea said. Similarity Score: 0.22879457947215806\n",
      "Answer Confidence Score: 7.875328302383423\n",
      "Average Exact Match: 0.34\n",
      "Average F1 Score: 0.5421409897292251\n"
     ]
    }
   ],
   "source": [
    "em_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Evaluate the QA model on the test questions\n",
    "for qa in question_answer:\n",
    "    question = qa[0]\n",
    "    expected_answer = [qa[1]]\n",
    "    article_id = qa[2]\n",
    "    article = data[data['id'] == int(article_id)]['article'].values[0]\n",
    "    result = answer_question1(query=question, article=article)\n",
    "    # result = answer_question2(query=question, article=article)\n",
    "    em_score = exact_match(result, expected_answer)\n",
    "    f1 = f1_score(result, expected_answer)\n",
    "    em_scores.append(em_score)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Compute the average EM and F1 scores\n",
    "average_em = np.mean(em_scores)\n",
    "average_f1 = np.mean(f1_scores)\n",
    "\n",
    "print(f\"Average Exact Match: {average_em}\")\n",
    "print(f\"Average F1 Score: {average_f1}\")\n",
    "\n",
    "# when using \"distilbert-base-cased-distilled-squad\" model, results are:\n",
    "# Average Exact Match: 0.28\n",
    "# Average F1 Score: 0.47248085248085253\n",
    "# when using \"bert-large-cased-whole-word-masking-finetuned-squad\" model, results are:\n",
    "# Average Exact Match: 0.34\n",
    "# Average F1 Score: 0.5421409897292251"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3a91b4",
   "metadata": {},
   "source": [
    "## B. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9e201d",
   "metadata": {},
   "source": [
    "1. Most code are modified on the basis of workshop code.\n",
    "2. Some doubts are solved by asking ChatGPT.\n",
    "3. Useful webpage:  \n",
    "https://huggingface.co/learn/nlp-course/chapter7/7?fw=pt\n",
    "4. Copilot is used when coding and debugging\n",
    "5. Useful links:  \n",
    "https://github.com/huggingface/neuralcoref/issues/357,  \n",
    "https://stackoverflow.com/questions/61269954/attribute-error-using-neuralcoref-in-colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7553c1",
   "metadata": {},
   "source": [
    "## C. Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c582df",
   "metadata": {},
   "source": [
    "Since I can't submit a .txt file, I just put questions and answers here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e801f8",
   "metadata": {},
   "source": [
    "('Who is the vice chairman of Samsung?', 17574) ('Jay Y. Lee', 24)\n",
    "('Who was the President during the conflict?', 17311) ('George W. Bush', 24)\n",
    "('Who is the Senator of Colorado?', 17311) ('Cory Gardner', 34)\n",
    "('What was the revolt's name in 2010?', 17311) ('Tea Party Revolt', 25)\n",
    "('When did Republicans get control back?', 17311) ('2010', 25)\n",
    "('Where is the senior Republican from?', 17311) ('Oklahoma', 7)\n",
    "('Who was the president during the Iraq War?', 17311) ('George W. Bush', 24)\n",
    "('What amount did Fox News offer?', 17339) ('20 Million', 26)\n",
    "('What show and program will Megyn Kelly host?', 17339) ('a daily daytime show and a Sunday newsmagazine program', 41)\n",
    "('What is Andrew Lack adding?', 17339) ('journalist schooled in the preferences and worldviews of the conservative Americans who helped elect Mr Trump', 11)\n",
    "('When is Donald Trump's inauguration?', 17339) ('Jan. 20', 2)\n",
    "('Who is an executive chairman of 21st Century Fox?', 17339) ('Rupert Murdoch', 15)\n",
    "('Is Douglas Brunt a novelist?', 17339) ('a novelist', 24)\n",
    "('Which city and Which Province was the shooting?', 17344) ('Panzhihua city, Sichuan Province', 2)\n",
    "('Who was embarrassed by the violence?', 17344) ('Xi Jinping', 4)\n",
    "('Chen Zhongshu is the head of what?', 17344) ('Panzhihua Land and Resources Bureau,', 6)\n",
    "('The shooting happened where?', 17344) ('a exhibition center', 2)\n",
    "('Which year did Zhang Yan start working there?', 17344) ('2006', 11)\n",
    "('Where is Panzhihua, which Province?', 17344) ('Sichuan Province', 2)\n",
    "('What kind of city is Panzhihua?', 17344) ('industrial city', 2)\n",
    "('What news app did Apple remove from its app store by the request of Chinese authorities?', 17368) ('The New York Times', 6)\n",
    "('What kind of job did Hans Rosling do?', 18465) ('doctor', 0)\n",
    "('Where did Hans Rosling die?', 18465) ('Uppsala, Sweden', 0)\n",
    "('When did Hans Rosling die?', 18465) ('Tuesday', 0)\n",
    "('How old was Hans Rosling when he died?', 18465) ('68', 0)\n",
    "('Is Hans Rosling still alive?', 18465) ('died on Tuesday in Uppsala, Sweden. He was 68', 0)\n",
    "('Where did Yves Ubelmann get a call from?', 17307) ('Syria', 0)\n",
    "('How old is Mr. Ubelmann?', 17307) ('36', 0)\n",
    "('Who did they get the permisson from for getting married?', 17292) ('her uncle, a judge', 0)\n",
    "('In which city did The Second Avenue subway open?', 17298) ('New York City', 0)\n",
    "('When was The Second Avenue first proposed?', 17298) ('1920s', 0)\n",
    "('When did Betsy Morris leave the 96th Street sation?', 17298) ('at noon', 0)\n",
    "('When was his work included in group shows?', 17285) ('1932 and 1934', 0)\n",
    "('How many shows did they do for Thierry Mugler in Paris?', 17308) ('five', 0)\n",
    "('When is Mr. Mulvaney's confirmation hearing is scheduled?', 17760) ('Jan. 24', 0)\n",
    "('What are the Knicks celebrating?', 18463) ('their 70th anniversary', 0)\n",
    "('Has Oakley been invited to any of the events?', 18463) ('No', 0)\n",
    "('How many seasons has Oakley played for the Knicks?', 18463) ('10', 0)\n",
    "('Did Dolan become the chairman of the Graden before Oakley's left?', 18463) ('No', 0)\n",
    "('What did a teammate urged Oakley to do?', 18463) ('to keep his voice down', 0)\n",
    "('Why did West Germany move gold abroad?', 18462) ('out of fear they would be seized by an invading Soviet army', 0)\n",
    "('How many gold bars had been transfered by plan according to Bundesbank's words?', 18462) ('$13 billion', 0)\n",
    "('When did the Belin Wall fall?', 18462) ('1989', 0)\n",
    "('What's the form of the only sold gold by Bundesbank??', 18462) ('commemorative coins', 0)\n",
    "('How many nuclear tests has North Korea conducted in the last decade?', 17287) ('five', 0)\n",
    "('How many ballistic missile tests in 2016 alone?', 17287) ('20', 0)\n",
    "('How far could a warhead of 1,100 to 1,300 pounds fly?', 17287) ('more than 7,400 miles', 0)\n",
    "('What test has North Korea complished in April?', 17287) ('successful ground test of an engine for an intercontinental ballistic missile', 0)\n",
    "('When did the UN Security Council impose new sanctiions against North Korea?', 17287) ('In November', 0)\n",
    "('Who is the leader of North Korea?', 17287) ('Kim', 0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
