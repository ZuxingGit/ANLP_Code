{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop Week 10: Question Answering\n",
    "\n",
    "#### Please follow the instructions in this code and the workshop Instructor.\n",
    "\n",
    "Read the first part and try to understand the code. Then run it, look at the outputs, then complete the tasks.\n",
    "\n",
    "Types of QA systems:\n",
    "\n",
    "    Extractive QA systems: These systems extract the answer directly from the given text by identifying the relevant section of text that contains the answer.\n",
    "\n",
    "    Abstractive QA systems: These systems generate a new answer by understanding the meaning of the question and synthesizing information from various sources.\n",
    "\n",
    "Classical (before deep neural learning) QA systems:\n",
    "\n",
    "    Information Retrieval based QA systems: These systems use information retrieval techniques to search for relevant documents and retrieve the most relevant answers.\n",
    "\n",
    "    Knowledge Graph based QA systems: These systems represent information in a structured format and use graph-based algorithms to answer questions.\n",
    "\n",
    "    Watson QA system: This system, developed by IBM, uses a combination of natural language processing, machine learning, and information retrieval techniques to answer questions in a wide range of domains.\n",
    "\n",
    "Evaluation of QA and Stanford Question Answering Dataset (SQuAD):\n",
    "\n",
    "SQuAD is a popular dataset used for evaluating QA systems. It consists of a large number of questions and answers, along with the corresponding passages of text that contain the answers. The dataset is used to evaluate the accuracy and performance of different QA systems.\n",
    "\n",
    "Language models for QA systems:\n",
    "\n",
    "    BiDAF (Bidirectional Attention Flow): This model uses a bidirectional attention mechanism to encode the question and the passage and identify the most relevant words and phrases.\n",
    "\n",
    "    Encoder-decoder transformers: These models use transformer networks to encode the input text and generate the output answer.\n",
    "\n",
    "    SpanBERT: This model is an extension of the BERT (Bidirectional Encoder Representations from Transformers) model and uses a span-based approach to answer questions. It considers all possible spans in the input text to generate the final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/bert-base-cased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer0: Paris\n",
      "Answer: Paris\n"
     ]
    }
   ],
   "source": [
    "# %pip install transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "# Load the BiDAF model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('deepset/bert-base-cased-squad2')\n",
    "model = AutoModelForQuestionAnswering.from_pretrained('deepset/bert-base-cased-squad2')\n",
    "\n",
    "# Define a sample question and passage\n",
    "question = \"What is the capital of France?\"\n",
    "passage = \"France, officially the French Republic, is a country primarily located in Western Europe, consisting of metropolitan France and several overseas regions and territories. Paris is the capital and most populous city of France.\"\n",
    "\n",
    "# Encode the question and passage using the tokenizer\n",
    "inputs = tokenizer.encode_plus(question, passage, return_tensors='pt', max_length=512, truncation=True, truncation_strategy='only_second')\n",
    "input_ids = inputs['input_ids']\n",
    "token_type_ids = inputs['token_type_ids']\n",
    "attention_mask = inputs['attention_mask']\n",
    "\n",
    "# Pass the encoded input through the BiDAF model\n",
    "outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, return_dict=True)\n",
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits\n",
    "\n",
    "# Decode the predicted start and end positions to get the answer\n",
    "start_index = torch.argmax(start_logits)\n",
    "end_index = torch.argmax(end_logits) + 1\n",
    "\n",
    "input_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "answer_tokens = input_ids[0][start_index:end_index]\n",
    "answer = tokenizer.decode(answer_tokens)\n",
    "print(\"Answer0:\", answer)\n",
    "\n",
    "# Skip over any tokens before the start position or after the end position\n",
    "for i, token in enumerate(answer_tokens):\n",
    "    if token == tokenizer.cls_token_id:\n",
    "        start_index += 1\n",
    "    elif token == tokenizer.sep_token_id:\n",
    "        end_index -= 1\n",
    "answer_tokens = input_ids[0][start_index:end_index]\n",
    "\n",
    "# Decode the answer tokens to get the final answer\n",
    "answer = tokenizer.decode(answer_tokens)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Construct Q/A system\n",
    "\n",
    "Task Description: In this task, you will be given a set of questions and a corresponding set of passages. Your goal is to use a QA model to find the answer to each question in its corresponding passage.\n",
    "\n",
    "Please review the code to understand it, run the first part, and complete the rest to make a QA system.\n",
    "\n",
    "Then follow the instructions from the workshop Instructor.\n",
    "\n",
    "\n",
    "Example Questions and Passages:\n",
    "\n",
    "Question 1: What is the capital of the United States?\n",
    "\n",
    "Passage 1: The capital of the United States is Washington, D.C. It is located on the east coast of the country, and is home to many important government buildings and monuments.\n",
    "\n",
    "Question 2: Who wrote the novel \"To Kill a Mockingbird\"?\n",
    "\n",
    "Passage 2: \"To Kill a Mockingbird\" is a novel written by Harper Lee. It was published in 1960 and has since become a classic of American literature.\n",
    "\n",
    "Question 3: What is the largest country in the world by area?\n",
    "\n",
    "Passage 3: Russia is the largest country in the world by area. It covers more than 17 million square kilometers and spans 11 time zones.\n",
    "\n",
    "Question 4: What is the capital of France?\n",
    "\n",
    "Passage 4: Paris is the capital and most populous city of France. It is located in the north-central part of the country, and is known for its rich history, art, and culture.\n",
    "\n",
    "Question 5: Who was the first president of the United States?\n",
    "\n",
    "Passage 5: George Washington was the first president of the United States. He served from 1789 to 1797, and is widely regarded as one of the most important figures in American history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: What is the capital of the United States?\n",
      "Passage 1: The capital of the United States is Washington, D.C. It is located on the east coast of the country, and is home to many important government buildings and monuments.\n",
      "Answer 1: Washington, D. C\n",
      "\n",
      "Question 2: Who wrote the novel \"To Kill a Mockingbird\"?\n",
      "Passage 2: \"To Kill a Mockingbird\" is a novel written by Harper Lee. It was published in 1960 and has since become a classic of American literature.\n",
      "Answer 2: Harper Lee\n",
      "\n",
      "Question 3: What is the largest country in the world by area?\n",
      "Passage 3: Russia is the largest country in the world by area. It covers more than 17 million square kilometers and spans 11 time zones.\n",
      "Answer 3: Russia\n",
      "\n",
      "Question 4: What is the capital of France?\n",
      "Passage 4: Paris is the capital and most populous city of France. It is located in the north-central part of the country, and is known for its rich history, art, and culture.\n",
      "Answer 4: Paris\n",
      "\n",
      "Question 5: Who was the first president of the United States?\n",
      "Passage 5: George Washington was the first president of the United States. He served from 1789 to 1797, and is widely regarded as one of the most important figures in American history.\n",
      "Answer 5: George Washington\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "# Load the QA model and tokenizer\n",
    "model_name = \"distilbert-base-cased-distilled-squad\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "# Define a set of questions and passages\n",
    "questions = [\n",
    "    \"What is the capital of the United States?\",\n",
    "    \"Who wrote the novel \\\"To Kill a Mockingbird\\\"?\",\n",
    "    \"What is the largest country in the world by area?\",\n",
    "    \"What is the capital of France?\",\n",
    "    \"Who was the first president of the United States?\"\n",
    "]\n",
    "passages = [\n",
    "    \"The capital of the United States is Washington, D.C. It is located on the east coast of the country, and is home to many important government buildings and monuments.\",\n",
    "    \"\\\"To Kill a Mockingbird\\\" is a novel written by Harper Lee. It was published in 1960 and has since become a classic of American literature.\",\n",
    "    \"Russia is the largest country in the world by area. It covers more than 17 million square kilometers and spans 11 time zones.\",\n",
    "    \"Paris is the capital and most populous city of France. It is located in the north-central part of the country, and is known for its rich history, art, and culture.\",\n",
    "    \"George Washington was the first president of the United States. He served from 1789 to 1797, and is widely regarded as one of the most important figures in American history.\"\n",
    "]\n",
    "\n",
    "# Loop over each question and passage, and use the QA model to find the answer\n",
    "for i, (question, passage) in enumerate(zip(questions, passages)):\n",
    "    # Encode the question and passage using the tokenizer\n",
    "    inputs = tokenizer.encode_plus(question, passage, return_tensors='pt', max_length=512, truncation=True, truncation_strategy='only_second')\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "\n",
    "    # Pass the encoded input through the QA model\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "    start_logits = outputs.start_logits\n",
    "    end_logits = outputs.end_logits\n",
    "\n",
    "\n",
    "    # Decode the predicted start and end positions to get the answer\n",
    "    start_index = torch.argmax(start_logits)\n",
    "    end_index = torch.argmax(end_logits) + 1\n",
    "\n",
    "    # Skip over any tokens before the start position or after the end position\n",
    "    for j, token_id in enumerate(input_ids[0]):\n",
    "        if j < start_index or j >= end_index:\n",
    "            input_ids[0][j] = tokenizer.pad_token_id\n",
    "\n",
    "    # Decode the answer from the corresponding tokens\n",
    "    answer_tokens = input_ids[0][start_index:end_index]\n",
    "    answer = tokenizer.decode(answer_tokens)\n",
    "\n",
    "    # Print the question, passage, and answer\n",
    "    print(\"Question {}: {}\".format(i+1, question))\n",
    "    print(\"Passage {}: {}\".format(i+1, passage))\n",
    "    print(\"Answer {}: {}\\n\".format(i+1, answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Use the QA code above\n",
    "\n",
    "Apply the code to one of Assignment 1 articles. Make a question, ground truth answer, and predict an answer using the code. Evaluate answer using precision/recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: Hans Rosling, a Swedish doctor who transformed himself into a   statistician by converting dry numbers into dynamic graphics that challenged preconceptions about global health and gloomy prospects for population growth, died on Tuesday in Uppsala, Sweden. He was 68.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: What was Hans Rosling's occupation?\n",
      "Answer 1: doctor\n",
      "\n",
      "Question 2: Where did Hans Rosling die?\n",
      "Answer 2: Uppsala, Sweden\n",
      "\n",
      "Question 3: When did Hans Rosling die?\n",
      "Answer 3: Tuesday\n",
      "\n",
      "Question 4: How old was Hans Rosling when he died?\n",
      "Answer 4: 68\n",
      "\n",
      "Question 5: Is Hans Rosling still alive?\n",
      "Answer 5: died on Tuesday in Uppsala, Sweden. He was 68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "article = \"Hans Rosling, a Swedish doctor who transformed himself into a   statistician by converting dry numbers into dynamic graphics that challenged preconceptions about global health and gloomy prospects for population growth, died on Tuesday in Uppsala, Sweden. He was 68.\"\n",
    "questions = [\"What was Hans Rosling's occupation?\",\n",
    "             \"Where did Hans Rosling die?\",\n",
    "             \"When did Hans Rosling die?\",\n",
    "            \"How old was Hans Rosling when he died?\",\n",
    "            \"Is Hans Rosling still alive?\"]\n",
    "print(\"Article: {}\".format(article))\n",
    "\n",
    "# Loop over each question against the same article\n",
    "for i, question in enumerate(questions):\n",
    "    # Encode the question and article using the tokenizer\n",
    "    inputs = tokenizer.encode_plus(question, article, return_tensors='pt', max_length=1024, truncation=True, truncation_strategy='only_second')\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "\n",
    "    # Pass the encoded input through the QA model\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "    start_logits = outputs.start_logits\n",
    "    end_logits = outputs.end_logits\n",
    "\n",
    "    # Decode the predicted start and end positions to get the answer\n",
    "    start_index = torch.argmax(start_logits)\n",
    "    end_index = torch.argmax(end_logits) + 1\n",
    "\n",
    "    # Skip over any tokens before the start position or after the end position\n",
    "    for j, token_id in enumerate(input_ids[0]):\n",
    "        if j < start_index or j >= end_index:\n",
    "            input_ids[0][j] = tokenizer.pad_token_id\n",
    "\n",
    "    # Decode the answer from the corresponding tokens\n",
    "    answer_tokens = input_ids[0][start_index:end_index]\n",
    "    answer = tokenizer.decode(answer_tokens)\n",
    "\n",
    "    # Print the question, article, and answer\n",
    "    print(\"Question {}: {}\".format(i+1, question))\n",
    "    print(\"Answer {}: {}\\n\".format(i+1, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the vice chairman of Samsung\n",
      "Answer: Jay Y. Lee\n"
     ]
    }
   ],
   "source": [
    "article = \"SEOUL, South Korea  ?   A special prosecutor investigating the corruption scandal that led to President Park  ?s impeachment summoned the de facto head of Samsung for questioning on Wednesday, calling him a bribery suspect. The de facto leader, Jay Y. Lee, the vice chairman of Samsung, will be questioned on Thursday, according to the special prosecutor?s office, which recommended that he also be investigated on suspicion of perjury. Mr. Lee effectively runs Samsung, South Korea?s largest conglomerate he is the son of its chairman, Lee   who has been incapacitated with health problems. He is expected to be asked whether   donations that Samsung made to two foundations controlled by Choi   a longtime friend of the president, amounted to bribes, and what role, if any, he played in the decision to give the money. Investigators at the special prosecutor?s office have questioned other senior Samsung executives as suspects about the bribery accusations. Neither Samsung nor Mr. Lee responded immediately to the announcement on Wednesday. Allegations that Ms. Park helped Ms. Choi extort millions in bribes from Samsung and other companies are at the heart of the corruption scandal that led to the National Assembly?s vote to impeach her last month. Since then, Ms. Park?s powers have been suspended, and she is on trial at the Constitutional Court, which will ultimately decide whether to end her presidency. Last month, Mr. Lee testified at a National Assembly hearing that he was not involved in the decision by Samsung to make the donations. He also said that the donations were not voluntary, suggesting that the company was a victim of extortion, not a participant in bribery. The reference on Wednesday to possible perjury charges against Mr. Lee stemmed from that testimony. The special prosecutor?s office said it had evidence that Mr. Lee had ?received a request for bribery from the president and ordered Samsung subsidiaries to send bribes to destinations designated by the president. ? It asked the National Assembly to file a perjury complaint against Mr. Lee, which would authorize the special prosecutor to open an investigation of that charge. Asked whether investigators would seek to arrest Mr. Lee on bribery charges, a spokesman for the special prosecutor?s office, Lee   said, ?All possibilities are open. ? In November, state prosecutors indicted Ms. Choi on charges of coercing 53 big businesses, including Samsung, to contribute $69 million to her two foundations. They identified Ms. Park as an accomplice but stopped short of filing any charges against the businesses, all of which insisted that they were under government pressure to donate. In its impeachment bill, the National Assembly asserted that the donations were bribes, made with the expectation of political favors from the president. The special prosecutor, which took over the investigations from the state prosecutors last month, has been looking into possible bribery charges against not only Ms. Park but the businesses, particularly Samsung. Ms. Park cannot be indicted while in office. Samsung gave the largest donations to Ms. Choi?s foundations, totaling $17 million. Unlike the other corporate contributors, it went beyond support for the foundations, signing an $18 million contract with a sports management company that Ms. Choi ran in Germany, to fund a program for training Korean equestrians, which mainly benefited Ms. Choi?s daughter. Samsung also contributed $1. 3 million to a winter sports program for young athletes that Ms. Choi and her nephew ran. Also on Wednesday, the special prosecutor?s office said it had acquired a tablet computer used by Ms. Choi that contained emails she exchanged with a Samsung executive. The emails contained information about the financial support provided by Samsung, the prosecutor?s office said. The special prosecutor has been investigating whether Samsung gave its support to Ms. Choi in exchange for a decision by the   National Pension Service to support a contentious merger of two Samsung affiliates in 2015. Moon   chairman of the pension fund, was arrested last month on charges that he illegally pressured the fund to back that merger when he was South Korea?s health and welfare minister. The national pension fund?s support was crucial for the merger, which analysts said helped Mr. Lee inherit control of Samsung from his father.\"\n",
    "question = \"Who is the vice chairman of Samsung\"\n",
    "\n",
    "# Encode the question and article using the tokenizer\n",
    "inputs = tokenizer.encode_plus(question, article, return_tensors='pt', max_length=2048, truncation=True, truncation_strategy='only_second')\n",
    "input_ids = inputs['input_ids']\n",
    "attention_mask = inputs['attention_mask']\n",
    "# Resize the input tensors to match the expected size\n",
    "input_ids = input_ids[:, :512]\n",
    "attention_mask = attention_mask[:, :512]\n",
    "\n",
    "# Pass the encoded input through the QA model\n",
    "outputs = model(input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits\n",
    "\n",
    "# Decode the predicted start and end positions to get the answer\n",
    "start_index = torch.argmax(start_logits)\n",
    "end_index = torch.argmax(end_logits) + 1\n",
    "\n",
    "# Skip over any tokens before the start position or after the end position\n",
    "for j, token_id in enumerate(input_ids[0]):\n",
    "    if j < start_index or j >= end_index:\n",
    "        input_ids[0][j] = tokenizer.pad_token_id\n",
    "\n",
    "# Decode the answer from the corresponding tokens\n",
    "answer_tokens = input_ids[0][start_index:end_index]\n",
    "answer = tokenizer.decode(answer_tokens)\n",
    "\n",
    "# Print the question, article, and answer\n",
    "print(\"Question: \" + question)\n",
    "print(\"Answer: \" + answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
